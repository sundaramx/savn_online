{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import main\n",
    "from models.savn import SAVN\n",
    "from models.basemodel import BaseModel\n",
    "from models.gcn import GCN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from runners.train_util import get_params\n",
    "from models.model_io import ModelOptions, ModelInput\n",
    "from utils.net_util import gpuify\n",
    "from utils.net_util import resnet_input_transform\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from runners.train_util import compute_learned_loss, SGD_step\n",
    "#import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH_DICT = {'SAVN' : 'pretrained_models/savn_pretrained.dat',\n",
    "                   'NON_ADAPTIVE_A3C': 'pretrained_models/nonadaptivea3c_pretrained.dat',\n",
    "                   'GCN':'pretrained_models/gcn_pretrained.dat' }\n",
    "GLOVE_FILE = './data/thor_glove/glove_map300d.hdf5'\n",
    "ACTION_LIST = ['MoveAhead', 'RotateLeft', 'RotateRight', 'LookUp', 'LookDown', 'Done']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeArgs():\n",
    "    def __init__(self, model='SAVN',glove_file=GLOVE_FILE,inner_lr=0.0001):\n",
    "        self.action_space = 6\n",
    "        self.glove_dim = 300\n",
    "        self.hidden_state_sz = 512\n",
    "        self.dropout_rate = 0.25\n",
    "        self.num_steps = 6 # initialized in main_eval.py\n",
    "        self.gpu_id = -1\n",
    "        self.learned_loss = True if model=='SAVN' else False\n",
    "        self.inner_lr = inner_lr\n",
    "        self.model = model\n",
    "        self.glove_file = GLOVE_FILE\n",
    "        \n",
    "        \n",
    "class Agent():\n",
    "    def __init__(self,args, model):\n",
    "        self.gpu_id = args.gpu_id\n",
    "        self.model = model\n",
    "        self.hidden = None #initialized in function call\n",
    "        self.last_action_probs = None #initialized in function call\n",
    "        self.resnet18 = None #initialized in function call\n",
    "        self.hidden_state_sz = args.hidden_state_sz\n",
    "        self.action_space = args.action_space\n",
    "        self.learned_loss = args.learned_loss\n",
    "        self.learned_input = None #initialized in function call\n",
    "        \n",
    "    def set_target(self,target_glove_embedding):\n",
    "        self.target_glove_embedding = target_glove_embedding\n",
    "        \n",
    "    def eval_at_state(self, model_options,frame):\n",
    "        model_input = ModelInput()\n",
    "#         if self.episode.current_frame is None:\n",
    "#             model_input.state = self.state()\n",
    "#         else:\n",
    "#             model_input.state = self.episode.current_frame\n",
    "        #process_frame to shape [1,3,224,224], for input to resnet18\n",
    "        processed_frame = self.preprocess_frame(resnet_input_transform(frame, 224).unsqueeze(0))\n",
    "        resnet18_features = self.resnet18(processed_frame)\n",
    "        \n",
    "        model_input.state = resnet18_features\n",
    "        model_input.hidden = self.hidden\n",
    "        model_input.target_class_embedding = gpuify(torch.Tensor(self.target_glove_embedding),gpu_id=self.gpu_id)\n",
    "        model_input.action_probs = self.last_action_probs\n",
    "\n",
    "        return model_input, self.model.forward(model_input, model_options)\n",
    "        \n",
    "    def reset_hidden(self):\n",
    "        if self.gpu_id >= 0:\n",
    "            with torch.cuda.device(self.gpu_id):\n",
    "                self.hidden = (\n",
    "                    torch.zeros(1, self.hidden_state_sz).cuda(),\n",
    "                    torch.zeros(1, self.hidden_state_sz).cuda(),\n",
    "                )\n",
    "        else:\n",
    "            self.hidden = (\n",
    "                torch.zeros(1, self.hidden_state_sz),\n",
    "                torch.zeros(1, self.hidden_state_sz),\n",
    "            )\n",
    "        self.last_action_probs = gpuify(\n",
    "            torch.zeros((1, self.action_space)), self.gpu_id\n",
    "        )\n",
    "        \n",
    "    def action(self, model_options, frame,training=False):\n",
    "        if training:\n",
    "            self.model.train()    #torch.nn\n",
    "        else:\n",
    "            self.model.eval()    \n",
    "\n",
    "        model_input, out = self.eval_at_state(model_options,frame)  \n",
    "        self.hidden = out.hidden\n",
    "        prob = F.softmax(out.logit, dim=1)\n",
    "        #print(prob)\n",
    "        action = prob.multinomial(1).data\n",
    "        #log_prob = F.log_softmax(out.logit, dim=1)\n",
    "        self.last_action_probs = prob\n",
    "        \n",
    "        if self.learned_loss:\n",
    "            \n",
    "            res = torch.cat((self.hidden[0], self.last_action_probs), dim=1)\n",
    "            #if DEBUG: print(\"agent/action  learned loss\", res.size())\n",
    "            if self.learned_input is None:\n",
    "                self.learned_input = res\n",
    "            else:\n",
    "                self.learned_input = torch.cat((self.learned_input, res), dim=0)\n",
    "        \n",
    "        return out.value, prob, action\n",
    "    \n",
    "    \n",
    "    \n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\" Preprocess the current frame for input into the model. \"\"\"\n",
    "        state = torch.Tensor(frame)\n",
    "        return gpuify(state, self.gpu_id)\n",
    "    \n",
    "    def init_resnet18(self):\n",
    "        \n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet18.children())[:-2]\n",
    "        self.resnet18 = nn.Sequential(*modules)\n",
    "        for p in self.resnet18.parameters():\n",
    "            p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embedding(glove_file):\n",
    "    glove_embedding_dict = {}\n",
    "    with h5py.File(glove_file, \"r\") as f:\n",
    "        for key in f.keys():\n",
    "            glove_embedding_dict[key] = f[key].value\n",
    "    return glove_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path,args):\n",
    "    if args.model=='NON_ADAPTIVE_A3C':\n",
    "        model = BaseModel(args)\n",
    "    elif args.model == 'GCN':\n",
    "        model = GCN(args)\n",
    "    else:\n",
    "        model = SAVN(args)\n",
    "    saved_state = torch.load(\n",
    "                model_path, map_location=lambda storage, loc: storage\n",
    "            )\n",
    "    model.load_state_dict(saved_state)\n",
    "    \n",
    "    model_options = ModelOptions()\n",
    "    params_list = [get_params(model, args.gpu_id)]\n",
    "    model_options.params = params_list[-1]\n",
    "    \n",
    "    return model, model_options\n",
    "    \n",
    "def init_agent(args, model):\n",
    "    agent = Agent(args, model)\n",
    "    agent.reset_hidden()\n",
    "    agent.init_resnet18()\n",
    "    return agent\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target(args,agent, controller, model_options, target, glove_embedding_dict, action_list, max_step=10):\n",
    "    agent.set_target(glove_embedding_dict[target])\n",
    "    event = controller.step(action='Initialize')\n",
    "    action = None\n",
    "    for i in range(max_step):\n",
    "        frame = event.frame\n",
    "        _,_, action = agent.action(model_options, frame)\n",
    "        print(i, action_list[action[0,0]])\n",
    "        if action[0,0] == 5: \n",
    "            print(\"Agent stopped after move \", i)\n",
    "            break\n",
    "            \n",
    "        event = controller.step(action=action_list[action[0,0]])\n",
    "        #print(event.metadata['lastActionSuccess'])\n",
    "            \n",
    "        #use gradient from interaction loss\n",
    "        if args.learned_loss:\n",
    "            if i % args.num_steps == 5 and i/args.num_steps < 4:\n",
    "                learned_loss = compute_learned_loss(args, agent, args.gpu_id, model_options)\n",
    "                inner_gradient = torch.autograd.grad(\n",
    "                        learned_loss[\"learned_loss\"],\n",
    "                        [v for _, v in model_options.params.items()],\n",
    "                        create_graph=True,\n",
    "                        retain_graph=True,\n",
    "                        allow_unused=True,\n",
    "                    )\n",
    "                print(\"gradient update\")\n",
    "                model_options.params = SGD_step(model_options.params, inner_gradient, args.inner_lr)\n",
    "            \n",
    "            \n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "    return event.frame\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai2thor.controller import Controller\n",
    "\n",
    "# Kitchens: FloorPlan1 - FloorPlan30\n",
    "# Living rooms: FloorPlan201 - FloorPlan230\n",
    "# Bedrooms: FloorPlan301 - FloorPlan330\n",
    "# Bathrooms: FloorPLan401 - FloorPlan430\n",
    "\n",
    "controller = Controller(scene='FloorPlan1', gridSize=0.25)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiuqixian/opt/miniconda3/envs/savn/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n",
      "/Users/jiuqixian/Desktop/savn/models/gcn.py:21: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LookDown\n",
      "1 RotateLeft\n",
      "2 RotateLeft\n",
      "3 RotateLeft\n",
      "4 RotateLeft\n",
      "5 RotateLeft\n",
      "6 MoveAhead\n",
      "7 MoveAhead\n",
      "8 MoveAhead\n",
      "9 RotateRight\n",
      "10 Done\n",
      "Agent stopped after move  10\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'Toaster'\n",
    "args = FakeArgs(model='GCN',inner_lr=0.0001)\n",
    "glove_embedding_dict = load_glove_embedding(args.glove_file)\n",
    "model, model_options = load_model(MODEL_PATH_DICT[args.model],args)\n",
    "agent = init_agent(args, model)\n",
    "final_frame = find_target(args, agent, controller, model_options, \n",
    "            target=TARGET, glove_embedding_dict = glove_embedding_dict,\n",
    "            action_list = ACTION_LIST,max_step=50)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Success 1: Fridge GarbageCan, Toaster\n",
    "#         3: Microwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ai2thor.server.Event at 0x7febe8afbf50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller.step(action=\"LookUp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ai2thor.server.Event at 0x7febc83f18d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller.step(action=\"RotateRight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AlarmClock', 'Apple', 'AppleSlice', 'Bathtub', 'Bed', 'Blinds', 'Book', 'Bowl', 'BowlDirty', 'BowlFilled', 'Box', 'Bread', 'BreadSliced', 'ButterKnife', 'Cabinet', 'Candle', 'CellPhone', 'Chair', 'Cloth', 'CoffeeMachine', 'Container', 'ContainerFull', 'CounterTop', 'CreditCard', 'Cup', 'Dirt', 'Egg', 'EggFried', 'EggShell', 'Fork', 'Fridge', 'GarbageCan', 'HousePlant', 'KeyChain', 'Knife', 'Lamp', 'Laptop', 'Lettuce', 'LettuceSliced', 'LightSwitch', 'Microwave', 'Mirror', 'Mug', 'MugFilled', 'Newspaper', 'Omelette', 'Painting', 'PaintingHanger', 'Pan', 'Pen', 'Pencil', 'Pillow', 'Plate', 'Plunger', 'Pot', 'Potato', 'PotatoSliced', 'RemoteControl', 'Sandwich', 'ScrubBrush', 'ShowerDoor', 'Sink', 'SoapBar', 'SoapBottle', 'Spoon', 'SportsEquipment', 'SprayBottle', 'Statue', 'StoveBurner', 'StoveKnob', 'TableTop', 'Television', 'TissueBox', 'Toaster', 'Toilet', 'ToiletPaper', 'Tomato', 'TomatoSliced', 'Towel', 'TowelHolder', 'VacuumCleaner', 'Watch', 'WateringCan'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
